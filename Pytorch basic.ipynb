{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a Pytorch studying material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic autograd example\n",
    "x = Variable(torch.Tensor([1]),requires_grad=True)\n",
    "w = Variable(torch.Tensor([5]),requires_grad=True)\n",
    "b = Variable(torch.Tensor([4]),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w*x + b\n",
    "\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 5\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: Parameter containing:\n",
      " 0.0863  0.1381  0.5358\n",
      "[torch.FloatTensor of size 1x3]\n",
      "\n",
      "b: Parameter containing:\n",
      "-0.5743\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<generator object Module.parameters at 0x7f31f4750e60>\n"
     ]
    }
   ],
   "source": [
    "# create tensor: x is the input and y is the GT output\n",
    "x = Variable(torch.randn(4,3))\n",
    "y = Variable(torch.randn(4,1))\n",
    "\n",
    "# we difine a linear layer\n",
    "linear = nn.Linear(3,1)\n",
    "\n",
    "print ('w:',linear.weight)\n",
    "print ('b:',linear.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0: 0.34271472692489624\n"
     ]
    }
   ],
   "source": [
    "#Build loss and caculate the optimal answer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.01)\n",
    "\n",
    "#predition with the layer and compute error\n",
    "\n",
    "pred = linear(x)\n",
    "loss = criterion(pred,y)\n",
    "\n",
    "print ('loss 0:',loss.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw: Variable containing:\n",
      "-0.3524  0.9534  1.0493\n",
      "[torch.FloatTensor of size 1x3]\n",
      "\n",
      "dL/db: Variable containing:\n",
      " 0.1626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BP \n",
    "loss.backward()\n",
    "print ('dL/dw:',linear.weight.grad)\n",
    "print ('dL/db:',linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1: 0.32324278354644775\n"
     ]
    }
   ],
   "source": [
    "#update parameters\n",
    "optimizer.step()\n",
    "pred = linear(x)\n",
    "loss = criterion(pred,y)\n",
    "\n",
    "print ('loss 1:',loss.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2: 0.30462440848350525\n"
     ]
    }
   ],
   "source": [
    "#update parameters one more\n",
    "optimizer.step()\n",
    "pred = linear(x)\n",
    "loss = criterion(pred,y)\n",
    "\n",
    "print ('loss 2:',loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [3 4]]\n",
      "\n",
      " 2  3\n",
      " 3  4\n",
      "[torch.LongTensor of size 2x2]\n",
      "\n",
      "[[2 3]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Tensor and numpy can be ver\n",
    "a = np.array([[2,3], [3,4]])\n",
    "b = torch.from_numpy(a)\n",
    "c = b.numpy()\n",
    "\n",
    "print (a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# torchvision.datasets stores many datasets like MNIST CIFAR COCO, which are stored as subclasses of it\n",
    "# torchvision.transforms including all kind precessing methods like scaling cropping flipping\n",
    "\n",
    "\n",
    "train_dset = dset.CIFAR10(root = '../data/',\n",
    "                          train = True,\n",
    "                          transform = transforms.ToTensor(),\n",
    "                          download = True)\n",
    "\n",
    "# let we get one data pair from the train dataset:\n",
    "image,label = train_dset[0]\n",
    "\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a very easy way to using the train Dataset\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset = train_dset,\n",
    "                                         batch_size = 100,\n",
    "                                         shuffle = True,\n",
    "                                         num_workers = 2)# num_workers is the num of subprocessing\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# so when you begin to iteration, that will be so easy\n",
    "\n",
    "for iamges, labels in data_loader:\n",
    "    # your trainning network\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you train the network with an outside dataset(custom dataset)\n",
    "\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        #TODO\n",
    "        #1.initialize the file path or list of filenames.\n",
    "        pass\n",
    "    def __getitem__(self,index):\n",
    "        #TODO\n",
    "        #1. read one data from the file e.g. using numpy.fromfile or PTL.Image.open\n",
    "        #2. preprocess the data e.g. torchvision.Transform\n",
    "        #3. return a data pair like image and label.\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # return the total size of your data\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    # Then you can build your custom data loader:\n",
    "    custom_dataset = CustomDataset()\n",
    "    data_loader = torch.utils.data.DataLoader(dataset= custom_dataset,\n",
    "                                             batch_size = 100,\n",
    "                                             shuffle = True,\n",
    "                                             num_workers = 2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/wpeng/.torch/models/resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Now if we need load a pretrained model\n",
    "\n",
    "resnet = torchvision.models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "# If you just want to finetuning for the top layer\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace the fully connected layer\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100) \n",
    "print(resnet.fc.in_features)\n",
    "# Random build a image and test the output size:\n",
    "images = Variable(torch.randn(10,3,224,224))\n",
    "outputs = resnet(images)\n",
    "\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load Model\n",
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.pkl')\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "# Save and load only the model parameters(recommended).\n",
    "torch.save(resnet.state_dict(), 'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
